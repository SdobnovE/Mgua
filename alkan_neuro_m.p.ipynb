{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import io\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "#нейронная сеть, слои которой соединены друг с другом\n",
    "\n",
    "from keras.layers import Dense\n",
    "#тип слоев, когда нейроны предыдущего уровня соединяются со всеми нейронами следующего уровня\n",
    "\n",
    "from keras.utils import np_utils\n",
    "#утилиты для numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"alkan/ALKAN.BLD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  1.,  0., ...,  2.,  1.,  1.],\n",
       "       [ 2.,  0.,  2., ...,  5.,  2.,  1.],\n",
       "       [ 2.,  0.,  2., ..., 10.,  4.,  2.],\n",
       "       ...,\n",
       "       [ 6.,  0.,  0., ..., 31., 13.,  2.],\n",
       "       [ 6.,  0.,  0., ..., 32., 14.,  2.],\n",
       "       [ 6.,  0.,  0., ..., 30., 12.,  2.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 210)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data.shape[0]\n",
    "m = data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74, 210)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(n,m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "word = 'A8 '\n",
    "with open('alkan/set-str/ALKAN.SET') as file:\n",
    "    for line in file:\n",
    "        if (word in line):\n",
    "            ape = float(line.split()[1])\n",
    "            l.append(ape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_del = []\n",
    "y = np.array(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(y.shape[0]):\n",
    "    if abs(y[i] - 0.0) < 1e-10:\n",
    "        index_del.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = np.delete(data, index_del, axis=0)\n",
    "new_y = np.delete(y, index_del, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56, 210)\n",
      "(56,)\n"
     ]
    }
   ],
   "source": [
    "print(new_data.shape)\n",
    "print(new_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(new_data, new_y, test_size=0.5, train_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(500, input_dim=X_train.shape[1], activation=\"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(700, input_dim=1234, activation=\"selu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", \n",
    "               optimizer=\"adam\", \n",
    "               metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/evgeny/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/550\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 12665.1095 - mean_absolute_error: 105.5778\n",
      "Epoch 2/550\n",
      "28/28 [==============================] - 0s 196us/step - loss: 7636.2390 - mean_absolute_error: 79.0049\n",
      "Epoch 3/550\n",
      "28/28 [==============================] - 0s 198us/step - loss: 4686.6606 - mean_absolute_error: 60.4178\n",
      "Epoch 4/550\n",
      "28/28 [==============================] - 0s 222us/step - loss: 2857.6385 - mean_absolute_error: 45.7341\n",
      "Epoch 5/550\n",
      "28/28 [==============================] - 0s 225us/step - loss: 2002.1880 - mean_absolute_error: 34.8857\n",
      "Epoch 6/550\n",
      "28/28 [==============================] - 0s 239us/step - loss: 1916.3486 - mean_absolute_error: 30.7991\n",
      "Epoch 7/550\n",
      "28/28 [==============================] - 0s 189us/step - loss: 2081.2291 - mean_absolute_error: 31.9526\n",
      "Epoch 8/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 2422.6392 - mean_absolute_error: 36.4658\n",
      "Epoch 9/550\n",
      "28/28 [==============================] - 0s 217us/step - loss: 2435.7532 - mean_absolute_error: 36.7187\n",
      "Epoch 10/550\n",
      "28/28 [==============================] - 0s 242us/step - loss: 2196.6125 - mean_absolute_error: 33.9153\n",
      "Epoch 11/550\n",
      "28/28 [==============================] - 0s 225us/step - loss: 1931.7096 - mean_absolute_error: 30.4053\n",
      "Epoch 12/550\n",
      "28/28 [==============================] - 0s 191us/step - loss: 1690.9619 - mean_absolute_error: 28.3154\n",
      "Epoch 13/550\n",
      "28/28 [==============================] - 0s 251us/step - loss: 1559.1766 - mean_absolute_error: 29.4227\n",
      "Epoch 14/550\n",
      "28/28 [==============================] - 0s 212us/step - loss: 1526.4202 - mean_absolute_error: 30.1144\n",
      "Epoch 15/550\n",
      "28/28 [==============================] - 0s 218us/step - loss: 1580.6686 - mean_absolute_error: 31.3908\n",
      "Epoch 16/550\n",
      "28/28 [==============================] - 0s 225us/step - loss: 1616.4268 - mean_absolute_error: 32.3309\n",
      "Epoch 17/550\n",
      "28/28 [==============================] - 0s 175us/step - loss: 1619.1846 - mean_absolute_error: 32.5631\n",
      "Epoch 18/550\n",
      "28/28 [==============================] - 0s 186us/step - loss: 1583.0386 - mean_absolute_error: 32.1791\n",
      "Epoch 19/550\n",
      "28/28 [==============================] - 0s 202us/step - loss: 1537.4114 - mean_absolute_error: 31.5372\n",
      "Epoch 20/550\n",
      "28/28 [==============================] - 0s 248us/step - loss: 1467.4308 - mean_absolute_error: 30.1992\n",
      "Epoch 21/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 1422.5793 - mean_absolute_error: 29.0076\n",
      "Epoch 22/550\n",
      "28/28 [==============================] - 0s 189us/step - loss: 1400.3570 - mean_absolute_error: 28.0355\n",
      "Epoch 23/550\n",
      "28/28 [==============================] - 0s 231us/step - loss: 1375.0875 - mean_absolute_error: 27.2485\n",
      "Epoch 24/550\n",
      "28/28 [==============================] - 0s 191us/step - loss: 1381.0115 - mean_absolute_error: 26.7112\n",
      "Epoch 25/550\n",
      "28/28 [==============================] - 0s 250us/step - loss: 1360.8550 - mean_absolute_error: 26.1801\n",
      "Epoch 26/550\n",
      "28/28 [==============================] - 0s 231us/step - loss: 1329.1638 - mean_absolute_error: 25.9859\n",
      "Epoch 27/550\n",
      "28/28 [==============================] - 0s 269us/step - loss: 1303.9024 - mean_absolute_error: 25.8316\n",
      "Epoch 28/550\n",
      "28/28 [==============================] - 0s 227us/step - loss: 1265.9659 - mean_absolute_error: 25.7346\n",
      "Epoch 29/550\n",
      "28/28 [==============================] - 0s 219us/step - loss: 1232.2207 - mean_absolute_error: 25.5825\n",
      "Epoch 30/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 1199.0787 - mean_absolute_error: 25.7231\n",
      "Epoch 31/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 1176.5572 - mean_absolute_error: 26.0955\n",
      "Epoch 32/550\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1175.2603 - mean_absolute_error: 26.7347\n",
      "Epoch 33/550\n",
      "28/28 [==============================] - 0s 178us/step - loss: 1133.0265 - mean_absolute_error: 26.1427\n",
      "Epoch 34/550\n",
      "28/28 [==============================] - 0s 183us/step - loss: 1078.7828 - mean_absolute_error: 24.8791\n",
      "Epoch 35/550\n",
      "28/28 [==============================] - 0s 330us/step - loss: 1049.8210 - mean_absolute_error: 23.5474\n",
      "Epoch 36/550\n",
      "28/28 [==============================] - 0s 340us/step - loss: 1025.5425 - mean_absolute_error: 22.9530\n",
      "Epoch 37/550\n",
      "28/28 [==============================] - 0s 205us/step - loss: 997.0091 - mean_absolute_error: 22.6739\n",
      "Epoch 38/550\n",
      "28/28 [==============================] - 0s 282us/step - loss: 952.3663 - mean_absolute_error: 22.1715\n",
      "Epoch 39/550\n",
      "28/28 [==============================] - 0s 220us/step - loss: 907.8026 - mean_absolute_error: 21.8262\n",
      "Epoch 40/550\n",
      "28/28 [==============================] - 0s 228us/step - loss: 866.4818 - mean_absolute_error: 21.5264\n",
      "Epoch 41/550\n",
      "28/28 [==============================] - 0s 212us/step - loss: 828.5332 - mean_absolute_error: 21.2121\n",
      "Epoch 42/550\n",
      "28/28 [==============================] - 0s 221us/step - loss: 799.6779 - mean_absolute_error: 21.1149\n",
      "Epoch 43/550\n",
      "28/28 [==============================] - 0s 202us/step - loss: 774.0160 - mean_absolute_error: 20.8625\n",
      "Epoch 44/550\n",
      "28/28 [==============================] - 0s 208us/step - loss: 721.4514 - mean_absolute_error: 20.0741\n",
      "Epoch 45/550\n",
      "28/28 [==============================] - 0s 251us/step - loss: 683.2219 - mean_absolute_error: 19.1855\n",
      "Epoch 46/550\n",
      "28/28 [==============================] - 0s 222us/step - loss: 648.4154 - mean_absolute_error: 18.3187\n",
      "Epoch 47/550\n",
      "28/28 [==============================] - 0s 266us/step - loss: 610.7874 - mean_absolute_error: 17.7433\n",
      "Epoch 48/550\n",
      "28/28 [==============================] - 0s 216us/step - loss: 571.3337 - mean_absolute_error: 17.1980\n",
      "Epoch 49/550\n",
      "28/28 [==============================] - 0s 207us/step - loss: 535.1618 - mean_absolute_error: 16.7152\n",
      "Epoch 50/550\n",
      "28/28 [==============================] - 0s 217us/step - loss: 512.8084 - mean_absolute_error: 16.6006\n",
      "Epoch 51/550\n",
      "28/28 [==============================] - 0s 212us/step - loss: 477.9510 - mean_absolute_error: 15.8403\n",
      "Epoch 52/550\n",
      "28/28 [==============================] - 0s 188us/step - loss: 435.4168 - mean_absolute_error: 14.7778\n",
      "Epoch 53/550\n",
      "28/28 [==============================] - 0s 185us/step - loss: 424.9114 - mean_absolute_error: 14.0928\n",
      "Epoch 54/550\n",
      "28/28 [==============================] - 0s 237us/step - loss: 411.9361 - mean_absolute_error: 13.9952\n",
      "Epoch 55/550\n",
      "28/28 [==============================] - 0s 241us/step - loss: 372.5927 - mean_absolute_error: 13.0603\n",
      "Epoch 56/550\n",
      "28/28 [==============================] - 0s 266us/step - loss: 346.5055 - mean_absolute_error: 13.1890\n",
      "Epoch 57/550\n",
      "28/28 [==============================] - 0s 193us/step - loss: 337.2411 - mean_absolute_error: 13.4305\n",
      "Epoch 58/550\n",
      "28/28 [==============================] - 0s 160us/step - loss: 303.7946 - mean_absolute_error: 12.0537\n",
      "Epoch 59/550\n",
      "28/28 [==============================] - 0s 189us/step - loss: 314.8623 - mean_absolute_error: 12.1617\n",
      "Epoch 60/550\n",
      "28/28 [==============================] - 0s 175us/step - loss: 278.8532 - mean_absolute_error: 11.1770\n",
      "Epoch 61/550\n",
      "28/28 [==============================] - 0s 204us/step - loss: 249.8602 - mean_absolute_error: 10.7091\n",
      "Epoch 62/550\n",
      "28/28 [==============================] - 0s 198us/step - loss: 251.9380 - mean_absolute_error: 11.5254\n",
      "Epoch 63/550\n",
      "28/28 [==============================] - 0s 191us/step - loss: 229.6678 - mean_absolute_error: 10.7726\n",
      "Epoch 64/550\n",
      "28/28 [==============================] - 0s 204us/step - loss: 204.6929 - mean_absolute_error: 9.7126\n",
      "Epoch 65/550\n",
      "28/28 [==============================] - 0s 175us/step - loss: 202.4048 - mean_absolute_error: 10.2214\n",
      "Epoch 66/550\n",
      "28/28 [==============================] - 0s 191us/step - loss: 187.9899 - mean_absolute_error: 9.5061\n",
      "Epoch 67/550\n",
      "28/28 [==============================] - 0s 215us/step - loss: 162.7875 - mean_absolute_error: 8.3610\n",
      "Epoch 68/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 157.0957 - mean_absolute_error: 8.7862\n",
      "Epoch 69/550\n",
      "28/28 [==============================] - 0s 204us/step - loss: 151.6644 - mean_absolute_error: 8.8636\n",
      "Epoch 70/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 136.6025 - mean_absolute_error: 7.8888\n",
      "Epoch 71/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 255us/step - loss: 129.4811 - mean_absolute_error: 7.7405\n",
      "Epoch 72/550\n",
      "28/28 [==============================] - 0s 203us/step - loss: 126.0422 - mean_absolute_error: 7.8049\n",
      "Epoch 73/550\n",
      "28/28 [==============================] - 0s 163us/step - loss: 111.8771 - mean_absolute_error: 7.2238\n",
      "Epoch 74/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 105.6665 - mean_absolute_error: 6.9808\n",
      "Epoch 75/550\n",
      "28/28 [==============================] - 0s 203us/step - loss: 97.2768 - mean_absolute_error: 6.7701\n",
      "Epoch 76/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 94.3611 - mean_absolute_error: 6.9365\n",
      "Epoch 77/550\n",
      "28/28 [==============================] - 0s 227us/step - loss: 86.7878 - mean_absolute_error: 6.4677\n",
      "Epoch 78/550\n",
      "28/28 [==============================] - 0s 201us/step - loss: 85.7740 - mean_absolute_error: 6.6059\n",
      "Epoch 79/550\n",
      "28/28 [==============================] - 0s 204us/step - loss: 82.0165 - mean_absolute_error: 6.5086\n",
      "Epoch 80/550\n",
      "28/28 [==============================] - 0s 181us/step - loss: 73.1997 - mean_absolute_error: 5.8433\n",
      "Epoch 81/550\n",
      "28/28 [==============================] - 0s 194us/step - loss: 70.0568 - mean_absolute_error: 5.8558\n",
      "Epoch 82/550\n",
      "28/28 [==============================] - 0s 225us/step - loss: 67.3794 - mean_absolute_error: 5.7560\n",
      "Epoch 83/550\n",
      "28/28 [==============================] - 0s 178us/step - loss: 62.3327 - mean_absolute_error: 5.2647\n",
      "Epoch 84/550\n",
      "28/28 [==============================] - 0s 189us/step - loss: 65.5849 - mean_absolute_error: 5.6430\n",
      "Epoch 85/550\n",
      "28/28 [==============================] - 0s 215us/step - loss: 61.1379 - mean_absolute_error: 5.3851\n",
      "Epoch 86/550\n",
      "28/28 [==============================] - 0s 188us/step - loss: 55.9751 - mean_absolute_error: 5.1412\n",
      "Epoch 87/550\n",
      "28/28 [==============================] - 0s 189us/step - loss: 53.2642 - mean_absolute_error: 4.7766\n",
      "Epoch 88/550\n",
      "28/28 [==============================] - 0s 198us/step - loss: 50.5144 - mean_absolute_error: 4.6146\n",
      "Epoch 89/550\n",
      "28/28 [==============================] - 0s 180us/step - loss: 50.8941 - mean_absolute_error: 4.7478\n",
      "Epoch 90/550\n",
      "28/28 [==============================] - 0s 186us/step - loss: 47.5181 - mean_absolute_error: 4.3986\n",
      "Epoch 91/550\n",
      "28/28 [==============================] - 0s 186us/step - loss: 43.9984 - mean_absolute_error: 4.0670\n",
      "Epoch 92/550\n",
      "28/28 [==============================] - 0s 169us/step - loss: 42.8962 - mean_absolute_error: 4.0207\n",
      "Epoch 93/550\n",
      "28/28 [==============================] - 0s 214us/step - loss: 41.0292 - mean_absolute_error: 3.9111\n",
      "Epoch 94/550\n",
      "28/28 [==============================] - 0s 193us/step - loss: 38.6685 - mean_absolute_error: 3.6546\n",
      "Epoch 95/550\n",
      "28/28 [==============================] - 0s 170us/step - loss: 37.3324 - mean_absolute_error: 3.7060\n",
      "Epoch 96/550\n",
      "28/28 [==============================] - 0s 187us/step - loss: 35.6635 - mean_absolute_error: 3.4662\n",
      "Epoch 97/550\n",
      "28/28 [==============================] - 0s 192us/step - loss: 34.4225 - mean_absolute_error: 3.4637\n",
      "Epoch 98/550\n",
      "28/28 [==============================] - 0s 172us/step - loss: 33.1069 - mean_absolute_error: 3.3593\n",
      "Epoch 99/550\n",
      "28/28 [==============================] - 0s 208us/step - loss: 31.7522 - mean_absolute_error: 3.3059\n",
      "Epoch 100/550\n",
      "28/28 [==============================] - 0s 188us/step - loss: 30.6210 - mean_absolute_error: 3.1260\n",
      "Epoch 101/550\n",
      "28/28 [==============================] - 0s 245us/step - loss: 29.5185 - mean_absolute_error: 3.2461\n",
      "Epoch 102/550\n",
      "28/28 [==============================] - 0s 199us/step - loss: 28.8802 - mean_absolute_error: 3.1261\n",
      "Epoch 103/550\n",
      "28/28 [==============================] - 0s 190us/step - loss: 26.4634 - mean_absolute_error: 2.9279\n",
      "Epoch 104/550\n",
      "28/28 [==============================] - 0s 222us/step - loss: 25.7986 - mean_absolute_error: 2.8093\n",
      "Epoch 105/550\n",
      "28/28 [==============================] - 0s 193us/step - loss: 25.0138 - mean_absolute_error: 2.7770\n",
      "Epoch 106/550\n",
      "28/28 [==============================] - 0s 226us/step - loss: 23.8350 - mean_absolute_error: 2.6247\n",
      "Epoch 107/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 23.0070 - mean_absolute_error: 2.7630\n",
      "Epoch 108/550\n",
      "28/28 [==============================] - 0s 165us/step - loss: 23.0090 - mean_absolute_error: 2.8368\n",
      "Epoch 109/550\n",
      "28/28 [==============================] - 0s 199us/step - loss: 21.4108 - mean_absolute_error: 2.5738\n",
      "Epoch 110/550\n",
      "28/28 [==============================] - 0s 206us/step - loss: 20.2057 - mean_absolute_error: 2.6010\n",
      "Epoch 111/550\n",
      "28/28 [==============================] - 0s 198us/step - loss: 20.2836 - mean_absolute_error: 2.6578\n",
      "Epoch 112/550\n",
      "28/28 [==============================] - 0s 181us/step - loss: 19.3530 - mean_absolute_error: 2.6511\n",
      "Epoch 113/550\n",
      "28/28 [==============================] - 0s 202us/step - loss: 19.1902 - mean_absolute_error: 2.7437\n",
      "Epoch 114/550\n",
      "28/28 [==============================] - 0s 237us/step - loss: 18.5238 - mean_absolute_error: 2.6578\n",
      "Epoch 115/550\n",
      "28/28 [==============================] - 0s 207us/step - loss: 17.3684 - mean_absolute_error: 2.4763\n",
      "Epoch 116/550\n",
      "28/28 [==============================] - 0s 177us/step - loss: 16.7272 - mean_absolute_error: 2.3121\n",
      "Epoch 117/550\n",
      "28/28 [==============================] - 0s 219us/step - loss: 16.0847 - mean_absolute_error: 2.3392\n",
      "Epoch 118/550\n",
      "28/28 [==============================] - 0s 203us/step - loss: 14.9425 - mean_absolute_error: 2.2702\n",
      "Epoch 119/550\n",
      "28/28 [==============================] - 0s 186us/step - loss: 14.6606 - mean_absolute_error: 2.2401\n",
      "Epoch 120/550\n",
      "28/28 [==============================] - 0s 223us/step - loss: 13.5189 - mean_absolute_error: 2.1531\n",
      "Epoch 121/550\n",
      "28/28 [==============================] - 0s 255us/step - loss: 13.4194 - mean_absolute_error: 2.0865\n",
      "Epoch 122/550\n",
      "28/28 [==============================] - 0s 202us/step - loss: 13.0259 - mean_absolute_error: 1.9830\n",
      "Epoch 123/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 12.2931 - mean_absolute_error: 2.2621\n",
      "Epoch 124/550\n",
      "28/28 [==============================] - 0s 262us/step - loss: 12.6673 - mean_absolute_error: 2.5556\n",
      "Epoch 125/550\n",
      "28/28 [==============================] - 0s 220us/step - loss: 10.9096 - mean_absolute_error: 1.9225\n",
      "Epoch 126/550\n",
      "28/28 [==============================] - 0s 216us/step - loss: 11.7140 - mean_absolute_error: 2.2588\n",
      "Epoch 127/550\n",
      "28/28 [==============================] - 0s 233us/step - loss: 10.5264 - mean_absolute_error: 1.9702\n",
      "Epoch 128/550\n",
      "28/28 [==============================] - 0s 227us/step - loss: 10.5213 - mean_absolute_error: 2.2480\n",
      "Epoch 129/550\n",
      "28/28 [==============================] - 0s 205us/step - loss: 10.3924 - mean_absolute_error: 2.2719\n",
      "Epoch 130/550\n",
      "28/28 [==============================] - 0s 195us/step - loss: 9.4658 - mean_absolute_error: 1.8471\n",
      "Epoch 131/550\n",
      "28/28 [==============================] - 0s 235us/step - loss: 9.9422 - mean_absolute_error: 2.1906\n",
      "Epoch 132/550\n",
      "28/28 [==============================] - 0s 222us/step - loss: 8.0993 - mean_absolute_error: 1.6714\n",
      "Epoch 133/550\n",
      "28/28 [==============================] - 0s 246us/step - loss: 9.4830 - mean_absolute_error: 2.2954\n",
      "Epoch 134/550\n",
      "28/28 [==============================] - 0s 279us/step - loss: 7.4411 - mean_absolute_error: 1.6114\n",
      "Epoch 135/550\n",
      "28/28 [==============================] - 0s 250us/step - loss: 9.3203 - mean_absolute_error: 2.2016\n",
      "Epoch 136/550\n",
      "28/28 [==============================] - 0s 213us/step - loss: 7.7607 - mean_absolute_error: 1.7473\n",
      "Epoch 137/550\n",
      "28/28 [==============================] - 0s 214us/step - loss: 8.0208 - mean_absolute_error: 2.1480\n",
      "Epoch 138/550\n",
      "28/28 [==============================] - 0s 212us/step - loss: 7.2369 - mean_absolute_error: 1.8153\n",
      "Epoch 139/550\n",
      "28/28 [==============================] - ETA: 0s - loss: 8.5513 - mean_absolute_error: 1.860 - 0s 195us/step - loss: 6.8407 - mean_absolute_error: 1.6559\n",
      "Epoch 140/550\n",
      "28/28 [==============================] - 0s 230us/step - loss: 6.5680 - mean_absolute_error: 1.6410\n",
      "Epoch 141/550\n",
      "28/28 [==============================] - 0s 199us/step - loss: 6.2245 - mean_absolute_error: 1.6464\n",
      "Epoch 142/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 224us/step - loss: 6.2628 - mean_absolute_error: 1.7614\n",
      "Epoch 143/550\n",
      "28/28 [==============================] - 0s 196us/step - loss: 5.2589 - mean_absolute_error: 1.3190\n",
      "Epoch 144/550\n",
      "28/28 [==============================] - 0s 207us/step - loss: 5.4900 - mean_absolute_error: 1.5210\n",
      "Epoch 145/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 5.3723 - mean_absolute_error: 1.4581\n",
      "Epoch 146/550\n",
      "28/28 [==============================] - 0s 256us/step - loss: 4.6951 - mean_absolute_error: 1.4846\n",
      "Epoch 147/550\n",
      "28/28 [==============================] - 0s 241us/step - loss: 4.9135 - mean_absolute_error: 1.4858\n",
      "Epoch 148/550\n",
      "28/28 [==============================] - 0s 255us/step - loss: 4.8558 - mean_absolute_error: 1.5024\n",
      "Epoch 149/550\n",
      "28/28 [==============================] - 0s 237us/step - loss: 4.8738 - mean_absolute_error: 1.5741\n",
      "Epoch 150/550\n",
      "28/28 [==============================] - 0s 195us/step - loss: 4.6406 - mean_absolute_error: 1.5498\n",
      "Epoch 151/550\n",
      "28/28 [==============================] - 0s 202us/step - loss: 4.0121 - mean_absolute_error: 1.2932\n",
      "Epoch 152/550\n",
      "28/28 [==============================] - 0s 216us/step - loss: 4.2087 - mean_absolute_error: 1.3411\n",
      "Epoch 153/550\n",
      "28/28 [==============================] - 0s 179us/step - loss: 3.5849 - mean_absolute_error: 1.2301\n",
      "Epoch 154/550\n",
      "28/28 [==============================] - 0s 191us/step - loss: 3.7342 - mean_absolute_error: 1.3285\n",
      "Epoch 155/550\n",
      "28/28 [==============================] - 0s 195us/step - loss: 3.7958 - mean_absolute_error: 1.2510\n",
      "Epoch 156/550\n",
      "28/28 [==============================] - 0s 177us/step - loss: 3.3216 - mean_absolute_error: 1.2248\n",
      "Epoch 157/550\n",
      "28/28 [==============================] - 0s 315us/step - loss: 3.3264 - mean_absolute_error: 1.1258\n",
      "Epoch 158/550\n",
      "28/28 [==============================] - 0s 170us/step - loss: 3.4182 - mean_absolute_error: 1.1397\n",
      "Epoch 159/550\n",
      "28/28 [==============================] - 0s 179us/step - loss: 2.9330 - mean_absolute_error: 1.0188\n",
      "Epoch 160/550\n",
      "28/28 [==============================] - 0s 196us/step - loss: 2.9244 - mean_absolute_error: 1.0035\n",
      "Epoch 161/550\n",
      "28/28 [==============================] - 0s 202us/step - loss: 2.7892 - mean_absolute_error: 0.9770\n",
      "Epoch 162/550\n",
      "28/28 [==============================] - 0s 204us/step - loss: 2.6642 - mean_absolute_error: 1.0147\n",
      "Epoch 163/550\n",
      "28/28 [==============================] - 0s 205us/step - loss: 2.5588 - mean_absolute_error: 0.9665\n",
      "Epoch 164/550\n",
      "28/28 [==============================] - 0s 200us/step - loss: 2.5255 - mean_absolute_error: 0.9674\n",
      "Epoch 165/550\n",
      "28/28 [==============================] - 0s 231us/step - loss: 2.4596 - mean_absolute_error: 0.9245\n",
      "Epoch 166/550\n",
      "28/28 [==============================] - 0s 190us/step - loss: 2.4227 - mean_absolute_error: 1.1519\n",
      "Epoch 167/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 2.2866 - mean_absolute_error: 1.0621\n",
      "Epoch 168/550\n",
      "28/28 [==============================] - 0s 194us/step - loss: 2.2446 - mean_absolute_error: 0.9585\n",
      "Epoch 169/550\n",
      "28/28 [==============================] - 0s 188us/step - loss: 2.4664 - mean_absolute_error: 1.1200\n",
      "Epoch 170/550\n",
      "28/28 [==============================] - 0s 213us/step - loss: 2.2027 - mean_absolute_error: 0.9066\n",
      "Epoch 171/550\n",
      "28/28 [==============================] - 0s 190us/step - loss: 2.0757 - mean_absolute_error: 1.0085\n",
      "Epoch 172/550\n",
      "28/28 [==============================] - 0s 201us/step - loss: 1.9798 - mean_absolute_error: 0.9350\n",
      "Epoch 173/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 2.0602 - mean_absolute_error: 0.9499\n",
      "Epoch 174/550\n",
      "28/28 [==============================] - 0s 220us/step - loss: 1.9635 - mean_absolute_error: 0.9789\n",
      "Epoch 175/550\n",
      "28/28 [==============================] - 0s 230us/step - loss: 1.6580 - mean_absolute_error: 0.8256\n",
      "Epoch 176/550\n",
      "28/28 [==============================] - 0s 226us/step - loss: 1.9857 - mean_absolute_error: 0.9293\n",
      "Epoch 177/550\n",
      "28/28 [==============================] - 0s 216us/step - loss: 1.6830 - mean_absolute_error: 0.7763\n",
      "Epoch 178/550\n",
      "28/28 [==============================] - 0s 200us/step - loss: 1.7891 - mean_absolute_error: 1.0170\n",
      "Epoch 179/550\n",
      "28/28 [==============================] - 0s 180us/step - loss: 1.5062 - mean_absolute_error: 0.7457\n",
      "Epoch 180/550\n",
      "28/28 [==============================] - 0s 215us/step - loss: 1.6276 - mean_absolute_error: 0.8342\n",
      "Epoch 181/550\n",
      "28/28 [==============================] - 0s 234us/step - loss: 1.4783 - mean_absolute_error: 0.7501\n",
      "Epoch 182/550\n",
      "28/28 [==============================] - 0s 240us/step - loss: 1.5933 - mean_absolute_error: 0.7807\n",
      "Epoch 183/550\n",
      "28/28 [==============================] - 0s 241us/step - loss: 1.4405 - mean_absolute_error: 0.6914\n",
      "Epoch 184/550\n",
      "28/28 [==============================] - 0s 198us/step - loss: 1.3561 - mean_absolute_error: 0.7108\n",
      "Epoch 185/550\n",
      "28/28 [==============================] - 0s 220us/step - loss: 1.2863 - mean_absolute_error: 0.6620\n",
      "Epoch 186/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 1.4580 - mean_absolute_error: 0.7306\n",
      "Epoch 187/550\n",
      "28/28 [==============================] - 0s 259us/step - loss: 1.3104 - mean_absolute_error: 0.7347\n",
      "Epoch 188/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 1.4497 - mean_absolute_error: 0.8130\n",
      "Epoch 189/550\n",
      "28/28 [==============================] - 0s 217us/step - loss: 1.3210 - mean_absolute_error: 0.8382\n",
      "Epoch 190/550\n",
      "28/28 [==============================] - 0s 221us/step - loss: 1.6410 - mean_absolute_error: 0.9672\n",
      "Epoch 191/550\n",
      "28/28 [==============================] - 0s 226us/step - loss: 1.2019 - mean_absolute_error: 0.6683\n",
      "Epoch 192/550\n",
      "28/28 [==============================] - 0s 241us/step - loss: 1.2279 - mean_absolute_error: 0.6894\n",
      "Epoch 193/550\n",
      "28/28 [==============================] - 0s 221us/step - loss: 1.0787 - mean_absolute_error: 0.5818\n",
      "Epoch 194/550\n",
      "28/28 [==============================] - 0s 265us/step - loss: 1.0564 - mean_absolute_error: 0.5856\n",
      "Epoch 195/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 1.0721 - mean_absolute_error: 0.6142\n",
      "Epoch 196/550\n",
      "28/28 [==============================] - 0s 206us/step - loss: 1.2053 - mean_absolute_error: 0.6398\n",
      "Epoch 197/550\n",
      "28/28 [==============================] - 0s 204us/step - loss: 1.0532 - mean_absolute_error: 0.7193\n",
      "Epoch 198/550\n",
      "28/28 [==============================] - 0s 254us/step - loss: 1.4497 - mean_absolute_error: 0.9360\n",
      "Epoch 199/550\n",
      "28/28 [==============================] - 0s 178us/step - loss: 1.5483 - mean_absolute_error: 0.8700\n",
      "Epoch 200/550\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.9679 - mean_absolute_error: 0.7614\n",
      "Epoch 201/550\n",
      "28/28 [==============================] - 0s 251us/step - loss: 2.0886 - mean_absolute_error: 1.0706\n",
      "Epoch 202/550\n",
      "28/28 [==============================] - 0s 264us/step - loss: 1.2848 - mean_absolute_error: 0.7237\n",
      "Epoch 203/550\n",
      "28/28 [==============================] - 0s 228us/step - loss: 1.8767 - mean_absolute_error: 1.1784\n",
      "Epoch 204/550\n",
      "28/28 [==============================] - 0s 196us/step - loss: 1.1231 - mean_absolute_error: 0.6475\n",
      "Epoch 205/550\n",
      "28/28 [==============================] - 0s 187us/step - loss: 1.9091 - mean_absolute_error: 1.0704\n",
      "Epoch 206/550\n",
      "28/28 [==============================] - 0s 185us/step - loss: 1.1245 - mean_absolute_error: 0.7547\n",
      "Epoch 207/550\n",
      "28/28 [==============================] - 0s 221us/step - loss: 1.5247 - mean_absolute_error: 0.9358\n",
      "Epoch 208/550\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.9570 - mean_absolute_error: 0.6782\n",
      "Epoch 209/550\n",
      "28/28 [==============================] - 0s 182us/step - loss: 1.3271 - mean_absolute_error: 0.8696\n",
      "Epoch 210/550\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.9658 - mean_absolute_error: 0.6780\n",
      "Epoch 211/550\n",
      "28/28 [==============================] - 0s 225us/step - loss: 1.2766 - mean_absolute_error: 0.8083\n",
      "Epoch 212/550\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.8276 - mean_absolute_error: 0.5574\n",
      "Epoch 213/550\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.8935 - mean_absolute_error: 0.6374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/550\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.9752 - mean_absolute_error: 0.5767\n",
      "Epoch 215/550\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.9349 - mean_absolute_error: 0.5863\n",
      "Epoch 216/550\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.9061 - mean_absolute_error: 0.6053\n",
      "Epoch 217/550\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.8349 - mean_absolute_error: 0.5859\n",
      "Epoch 218/550\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.7994 - mean_absolute_error: 0.5853\n",
      "Epoch 219/550\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.7514 - mean_absolute_error: 0.4896\n",
      "Epoch 220/550\n",
      "28/28 [==============================] - 0s 162us/step - loss: 0.7087 - mean_absolute_error: 0.5078\n",
      "Epoch 221/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 1.0941 - mean_absolute_error: 0.7044\n",
      "Epoch 222/550\n",
      "28/28 [==============================] - 0s 180us/step - loss: 0.9537 - mean_absolute_error: 0.5837\n",
      "Epoch 223/550\n",
      "28/28 [==============================] - 0s 170us/step - loss: 0.9794 - mean_absolute_error: 0.6515\n",
      "Epoch 224/550\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.6796 - mean_absolute_error: 0.4487\n",
      "Epoch 225/550\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.6601 - mean_absolute_error: 0.4550\n",
      "Epoch 226/550\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.6437 - mean_absolute_error: 0.4151\n",
      "Epoch 227/550\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.6381 - mean_absolute_error: 0.4013\n",
      "Epoch 228/550\n",
      "28/28 [==============================] - 0s 173us/step - loss: 0.6371 - mean_absolute_error: 0.4062\n",
      "Epoch 229/550\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.6683 - mean_absolute_error: 0.4140\n",
      "Epoch 230/550\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.6837 - mean_absolute_error: 0.4907\n",
      "Epoch 231/550\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.6731 - mean_absolute_error: 0.4502\n",
      "Epoch 232/550\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.6155 - mean_absolute_error: 0.4730\n",
      "Epoch 233/550\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.6130 - mean_absolute_error: 0.4098\n",
      "Epoch 234/550\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.6712 - mean_absolute_error: 0.4032\n",
      "Epoch 235/550\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.6796 - mean_absolute_error: 0.4696\n",
      "Epoch 236/550\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.9380 - mean_absolute_error: 0.638 - 0s 236us/step - loss: 0.7719 - mean_absolute_error: 0.6011\n",
      "Epoch 237/550\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.5789 - mean_absolute_error: 0.3861\n",
      "Epoch 238/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.8242 - mean_absolute_error: 0.6752\n",
      "Epoch 239/550\n",
      "28/28 [==============================] - 0s 289us/step - loss: 0.5704 - mean_absolute_error: 0.3767\n",
      "Epoch 240/550\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.7042 - mean_absolute_error: 0.5656\n",
      "Epoch 241/550\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.6853 - mean_absolute_error: 0.4833\n",
      "Epoch 242/550\n",
      "28/28 [==============================] - 0s 194us/step - loss: 0.6679 - mean_absolute_error: 0.4486\n",
      "Epoch 243/550\n",
      "28/28 [==============================] - 0s 270us/step - loss: 0.6884 - mean_absolute_error: 0.5988\n",
      "Epoch 244/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.6374 - mean_absolute_error: 0.5417\n",
      "Epoch 245/550\n",
      "28/28 [==============================] - 0s 281us/step - loss: 0.6474 - mean_absolute_error: 0.5130\n",
      "Epoch 246/550\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.5589 - mean_absolute_error: 0.4431\n",
      "Epoch 247/550\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.7475 - mean_absolute_error: 0.5422\n",
      "Epoch 248/550\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.5273 - mean_absolute_error: 0.3925\n",
      "Epoch 249/550\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.5835 - mean_absolute_error: 0.5267\n",
      "Epoch 250/550\n",
      "28/28 [==============================] - 0s 304us/step - loss: 0.5634 - mean_absolute_error: 0.4309\n",
      "Epoch 251/550\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.5454 - mean_absolute_error: 0.4342\n",
      "Epoch 252/550\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.7756 - mean_absolute_error: 0.6806\n",
      "Epoch 253/550\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.6690 - mean_absolute_error: 0.4817\n",
      "Epoch 254/550\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.5455 - mean_absolute_error: 0.4957\n",
      "Epoch 255/550\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.7140 - mean_absolute_error: 0.5836\n",
      "Epoch 256/550\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.6708 - mean_absolute_error: 0.4903\n",
      "Epoch 257/550\n",
      "28/28 [==============================] - 0s 179us/step - loss: 0.6654 - mean_absolute_error: 0.5301\n",
      "Epoch 258/550\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.4987 - mean_absolute_error: 0.3816\n",
      "Epoch 259/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.4837 - mean_absolute_error: 0.3663\n",
      "Epoch 260/550\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.4964 - mean_absolute_error: 0.3864\n",
      "Epoch 261/550\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.5198 - mean_absolute_error: 0.4620\n",
      "Epoch 262/550\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.4833 - mean_absolute_error: 0.3571\n",
      "Epoch 263/550\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.4700 - mean_absolute_error: 0.3672\n",
      "Epoch 264/550\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.4979 - mean_absolute_error: 0.4034\n",
      "Epoch 265/550\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.4728 - mean_absolute_error: 0.3790\n",
      "Epoch 266/550\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.5149 - mean_absolute_error: 0.3912\n",
      "Epoch 267/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.4499 - mean_absolute_error: 0.3430\n",
      "Epoch 268/550\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.4350 - mean_absolute_error: 0.3241\n",
      "Epoch 269/550\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.4798 - mean_absolute_error: 0.3996\n",
      "Epoch 270/550\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.4470 - mean_absolute_error: 0.4093\n",
      "Epoch 271/550\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.4014 - mean_absolute_error: 0.3016\n",
      "Epoch 272/550\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.4340 - mean_absolute_error: 0.3738\n",
      "Epoch 273/550\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.4409 - mean_absolute_error: 0.3459\n",
      "Epoch 274/550\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.4296 - mean_absolute_error: 0.3084\n",
      "Epoch 275/550\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.3857 - mean_absolute_error: 0.2911\n",
      "Epoch 276/550\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.3865 - mean_absolute_error: 0.3032\n",
      "Epoch 277/550\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.4159 - mean_absolute_error: 0.3286\n",
      "Epoch 278/550\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.3587 - mean_absolute_error: 0.2545\n",
      "Epoch 279/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.4499 - mean_absolute_error: 0.3530\n",
      "Epoch 280/550\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.3992 - mean_absolute_error: 0.2646\n",
      "Epoch 281/550\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.3947 - mean_absolute_error: 0.3058\n",
      "Epoch 282/550\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.3976 - mean_absolute_error: 0.2550\n",
      "Epoch 283/550\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.3867 - mean_absolute_error: 0.2608\n",
      "Epoch 284/550\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.3786 - mean_absolute_error: 0.2560\n",
      "Epoch 285/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 213us/step - loss: 0.3551 - mean_absolute_error: 0.2465\n",
      "Epoch 286/550\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.3624 - mean_absolute_error: 0.2921\n",
      "Epoch 287/550\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.3609 - mean_absolute_error: 0.2591\n",
      "Epoch 288/550\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.3411 - mean_absolute_error: 0.2583\n",
      "Epoch 289/550\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.4042 - mean_absolute_error: 0.3608\n",
      "Epoch 290/550\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.3592 - mean_absolute_error: 0.2805\n",
      "Epoch 291/550\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.3721 - mean_absolute_error: 0.3688\n",
      "Epoch 292/550\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.3696 - mean_absolute_error: 0.2944\n",
      "Epoch 293/550\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.3363 - mean_absolute_error: 0.2860\n",
      "Epoch 294/550\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.4296 - mean_absolute_error: 0.4249\n",
      "Epoch 295/550\n",
      "28/28 [==============================] - 0s 263us/step - loss: 0.3641 - mean_absolute_error: 0.3603\n",
      "Epoch 296/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.3628 - mean_absolute_error: 0.3746\n",
      "Epoch 297/550\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.4392 - mean_absolute_error: 0.4492\n",
      "Epoch 298/550\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.3073 - mean_absolute_error: 0.2680\n",
      "Epoch 299/550\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.4839 - mean_absolute_error: 0.4910\n",
      "Epoch 300/550\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.3208 - mean_absolute_error: 0.2946\n",
      "Epoch 301/550\n",
      "28/28 [==============================] - 0s 299us/step - loss: 0.3622 - mean_absolute_error: 0.3746\n",
      "Epoch 302/550\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.3316 - mean_absolute_error: 0.3115\n",
      "Epoch 303/550\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.3400 - mean_absolute_error: 0.2973\n",
      "Epoch 304/550\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.2929 - mean_absolute_error: 0.2414\n",
      "Epoch 305/550\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.3288 - mean_absolute_error: 0.2877\n",
      "Epoch 306/550\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.3257 - mean_absolute_error: 0.2694\n",
      "Epoch 307/550\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.3115 - mean_absolute_error: 0.2716\n",
      "Epoch 308/550\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.2988 - mean_absolute_error: 0.2537\n",
      "Epoch 309/550\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.3226 - mean_absolute_error: 0.2715\n",
      "Epoch 310/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.2886 - mean_absolute_error: 0.2466\n",
      "Epoch 311/550\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.2994 - mean_absolute_error: 0.3127\n",
      "Epoch 312/550\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.3175 - mean_absolute_error: 0.3388\n",
      "Epoch 313/550\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.2935 - mean_absolute_error: 0.2912\n",
      "Epoch 314/550\n",
      "28/28 [==============================] - 0s 216us/step - loss: 0.3315 - mean_absolute_error: 0.3823\n",
      "Epoch 315/550\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.2997 - mean_absolute_error: 0.2844\n",
      "Epoch 316/550\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.2922 - mean_absolute_error: 0.2823\n",
      "Epoch 317/550\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.2998 - mean_absolute_error: 0.3412\n",
      "Epoch 318/550\n",
      "28/28 [==============================] - 0s 166us/step - loss: 0.2705 - mean_absolute_error: 0.2643\n",
      "Epoch 319/550\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.2824 - mean_absolute_error: 0.2503\n",
      "Epoch 320/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.2736 - mean_absolute_error: 0.2717\n",
      "Epoch 321/550\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.2813 - mean_absolute_error: 0.2961\n",
      "Epoch 322/550\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.2602 - mean_absolute_error: 0.2880\n",
      "Epoch 323/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.2454 - mean_absolute_error: 0.2652\n",
      "Epoch 324/550\n",
      "28/28 [==============================] - 0s 165us/step - loss: 0.3205 - mean_absolute_error: 0.3596\n",
      "Epoch 325/550\n",
      "28/28 [==============================] - 0s 238us/step - loss: 0.3585 - mean_absolute_error: 0.3321\n",
      "Epoch 326/550\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.2308 - mean_absolute_error: 0.2447\n",
      "Epoch 327/550\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.3937 - mean_absolute_error: 0.4072\n",
      "Epoch 328/550\n",
      "28/28 [==============================] - 0s 270us/step - loss: 0.3151 - mean_absolute_error: 0.3204\n",
      "Epoch 329/550\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.2352 - mean_absolute_error: 0.2643\n",
      "Epoch 330/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.3940 - mean_absolute_error: 0.4169\n",
      "Epoch 331/550\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.2879 - mean_absolute_error: 0.2670\n",
      "Epoch 332/550\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.3693 - mean_absolute_error: 0.3443\n",
      "Epoch 333/550\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.2770 - mean_absolute_error: 0.3300\n",
      "Epoch 334/550\n",
      "28/28 [==============================] - 0s 161us/step - loss: 0.2413 - mean_absolute_error: 0.3076\n",
      "Epoch 335/550\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.3354 - mean_absolute_error: 0.4194\n",
      "Epoch 336/550\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.2907 - mean_absolute_error: 0.3391\n",
      "Epoch 337/550\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.2959 - mean_absolute_error: 0.3260\n",
      "Epoch 338/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.3656 - mean_absolute_error: 0.4478\n",
      "Epoch 339/550\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.4349 - mean_absolute_error: 0.4826\n",
      "Epoch 340/550\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.3417 - mean_absolute_error: 0.3877\n",
      "Epoch 341/550\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.6020 - mean_absolute_error: 0.6190\n",
      "Epoch 342/550\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.3489 - mean_absolute_error: 0.4322\n",
      "Epoch 343/550\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.2926 - mean_absolute_error: 0.3956\n",
      "Epoch 344/550\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.3089 - mean_absolute_error: 0.3946\n",
      "Epoch 345/550\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.2351 - mean_absolute_error: 0.2867\n",
      "Epoch 346/550\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.3153 - mean_absolute_error: 0.3761\n",
      "Epoch 347/550\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.2538 - mean_absolute_error: 0.3453\n",
      "Epoch 348/550\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.2166 - mean_absolute_error: 0.2831\n",
      "Epoch 349/550\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.2484 - mean_absolute_error: 0.3022\n",
      "Epoch 350/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.2093 - mean_absolute_error: 0.2440\n",
      "Epoch 351/550\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.2001 - mean_absolute_error: 0.2459\n",
      "Epoch 352/550\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.2192 - mean_absolute_error: 0.2884\n",
      "Epoch 353/550\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.2171 - mean_absolute_error: 0.2540\n",
      "Epoch 354/550\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.1823 - mean_absolute_error: 0.2184\n",
      "Epoch 355/550\n",
      "28/28 [==============================] - 0s 329us/step - loss: 0.2170 - mean_absolute_error: 0.2617\n",
      "Epoch 356/550\n",
      "28/28 [==============================] - 0s 265us/step - loss: 0.2952 - mean_absolute_error: 0.4433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 357/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.1974 - mean_absolute_error: 0.2886\n",
      "Epoch 358/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.2757 - mean_absolute_error: 0.4255\n",
      "Epoch 359/550\n",
      "28/28 [==============================] - 0s 293us/step - loss: 0.3349 - mean_absolute_error: 0.4238\n",
      "Epoch 360/550\n",
      "28/28 [==============================] - 0s 182us/step - loss: 0.1810 - mean_absolute_error: 0.2836\n",
      "Epoch 361/550\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.3678 - mean_absolute_error: 0.5171\n",
      "Epoch 362/550\n",
      "28/28 [==============================] - 0s 268us/step - loss: 0.2539 - mean_absolute_error: 0.3690\n",
      "Epoch 363/550\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.3785 - mean_absolute_error: 0.4539\n",
      "Epoch 364/550\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.2158 - mean_absolute_error: 0.2993\n",
      "Epoch 365/550\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.1617 - mean_absolute_error: 0.2341\n",
      "Epoch 366/550\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.1719 - mean_absolute_error: 0.2205\n",
      "Epoch 367/550\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.1993 - mean_absolute_error: 0.2613\n",
      "Epoch 368/550\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.1886 - mean_absolute_error: 0.2825\n",
      "Epoch 369/550\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.1780 - mean_absolute_error: 0.2645\n",
      "Epoch 370/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.2725 - mean_absolute_error: 0.4312\n",
      "Epoch 371/550\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.1761 - mean_absolute_error: 0.2130\n",
      "Epoch 372/550\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.1735 - mean_absolute_error: 0.2616\n",
      "Epoch 373/550\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.2269 - mean_absolute_error: 0.3260\n",
      "Epoch 374/550\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.1662 - mean_absolute_error: 0.2794\n",
      "Epoch 375/550\n",
      "28/28 [==============================] - 0s 176us/step - loss: 0.1888 - mean_absolute_error: 0.3074\n",
      "Epoch 376/550\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.1846 - mean_absolute_error: 0.2968\n",
      "Epoch 377/550\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.1941 - mean_absolute_error: 0.2432\n",
      "Epoch 378/550\n",
      "28/28 [==============================] - 0s 260us/step - loss: 0.1337 - mean_absolute_error: 0.2045\n",
      "Epoch 379/550\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.1830 - mean_absolute_error: 0.2603\n",
      "Epoch 380/550\n",
      "28/28 [==============================] - 0s 320us/step - loss: 0.1649 - mean_absolute_error: 0.2384\n",
      "Epoch 381/550\n",
      "28/28 [==============================] - 0s 277us/step - loss: 0.1728 - mean_absolute_error: 0.3096\n",
      "Epoch 382/550\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.1296 - mean_absolute_error: 0.1861\n",
      "Epoch 383/550\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.1459 - mean_absolute_error: 0.2365\n",
      "Epoch 384/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.1773 - mean_absolute_error: 0.2607\n",
      "Epoch 385/550\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.1874 - mean_absolute_error: 0.2575\n",
      "Epoch 386/550\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.1611 - mean_absolute_error: 0.1919\n",
      "Epoch 387/550\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.1160 - mean_absolute_error: 0.1782\n",
      "Epoch 388/550\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.2306 - mean_absolute_error: 0.3647\n",
      "Epoch 389/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.1683 - mean_absolute_error: 0.3081\n",
      "Epoch 390/550\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.1949 - mean_absolute_error: 0.3513\n",
      "Epoch 391/550\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.3142 - mean_absolute_error: 0.4782\n",
      "Epoch 392/550\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.1290 - mean_absolute_error: 0.2494\n",
      "Epoch 393/550\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.2877 - mean_absolute_error: 0.3916\n",
      "Epoch 394/550\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.2276 - mean_absolute_error: 0.3237\n",
      "Epoch 395/550\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.1551 - mean_absolute_error: 0.2393\n",
      "Epoch 396/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.2115 - mean_absolute_error: 0.2938\n",
      "Epoch 397/550\n",
      "28/28 [==============================] - 0s 329us/step - loss: 0.4386 - mean_absolute_error: 0.5713\n",
      "Epoch 398/550\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.2846 - mean_absolute_error: 0.3777\n",
      "Epoch 399/550\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.3258 - mean_absolute_error: 0.4547\n",
      "Epoch 400/550\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.4870 - mean_absolute_error: 0.6168\n",
      "Epoch 401/550\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.2358 - mean_absolute_error: 0.3865\n",
      "Epoch 402/550\n",
      "28/28 [==============================] - 0s 300us/step - loss: 0.3224 - mean_absolute_error: 0.4416\n",
      "Epoch 403/550\n",
      "28/28 [==============================] - 0s 208us/step - loss: 0.4738 - mean_absolute_error: 0.6031\n",
      "Epoch 404/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.2262 - mean_absolute_error: 0.3110\n",
      "Epoch 405/550\n",
      "28/28 [==============================] - 0s 274us/step - loss: 0.1891 - mean_absolute_error: 0.3718\n",
      "Epoch 406/550\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.3699 - mean_absolute_error: 0.4671\n",
      "Epoch 407/550\n",
      "28/28 [==============================] - 0s 225us/step - loss: 0.4541 - mean_absolute_error: 0.5934\n",
      "Epoch 408/550\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.1688 - mean_absolute_error: 0.3381\n",
      "Epoch 409/550\n",
      "28/28 [==============================] - 0s 262us/step - loss: 0.5948 - mean_absolute_error: 0.7130\n",
      "Epoch 410/550\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.4581 - mean_absolute_error: 0.4923\n",
      "Epoch 411/550\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.1265 - mean_absolute_error: 0.2735\n",
      "Epoch 412/550\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.6669 - mean_absolute_error: 0.7168\n",
      "Epoch 413/550\n",
      "28/28 [==============================] - 0s 308us/step - loss: 0.5254 - mean_absolute_error: 0.6418\n",
      "Epoch 414/550\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.2368 - mean_absolute_error: 0.4207\n",
      "Epoch 415/550\n",
      "28/28 [==============================] - 0s 188us/step - loss: 0.6581 - mean_absolute_error: 0.6763\n",
      "Epoch 416/550\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.3364 - mean_absolute_error: 0.4574\n",
      "Epoch 417/550\n",
      "28/28 [==============================] - 0s 210us/step - loss: 0.1825 - mean_absolute_error: 0.3131\n",
      "Epoch 418/550\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.3148 - mean_absolute_error: 0.5035\n",
      "Epoch 419/550\n",
      "28/28 [==============================] - 0s 192us/step - loss: 0.4257 - mean_absolute_error: 0.4556\n",
      "Epoch 420/550\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.2745 - mean_absolute_error: 0.3495\n",
      "Epoch 421/550\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.1871 - mean_absolute_error: 0.3230\n",
      "Epoch 422/550\n",
      "28/28 [==============================] - 0s 205us/step - loss: 0.6157 - mean_absolute_error: 0.6885\n",
      "Epoch 423/550\n",
      "28/28 [==============================] - 0s 237us/step - loss: 0.2732 - mean_absolute_error: 0.4091\n",
      "Epoch 424/550\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.1989 - mean_absolute_error: 0.3534\n",
      "Epoch 425/550\n",
      "28/28 [==============================] - 0s 257us/step - loss: 0.7286 - mean_absolute_error: 0.6946\n",
      "Epoch 426/550\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.3798 - mean_absolute_error: 0.5322\n",
      "Epoch 427/550\n",
      "28/28 [==============================] - 0s 206us/step - loss: 0.3417 - mean_absolute_error: 0.4849\n",
      "Epoch 428/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 224us/step - loss: 0.7259 - mean_absolute_error: 0.7935\n",
      "Epoch 429/550\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.5364 - mean_absolute_error: 0.5647\n",
      "Epoch 430/550\n",
      "28/28 [==============================] - 0s 275us/step - loss: 0.3224 - mean_absolute_error: 0.4640\n",
      "Epoch 431/550\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.6709 - mean_absolute_error: 0.6758\n",
      "Epoch 432/550\n",
      "28/28 [==============================] - 0s 214us/step - loss: 0.4702 - mean_absolute_error: 0.5908\n",
      "Epoch 433/550\n",
      "28/28 [==============================] - 0s 221us/step - loss: 0.3253 - mean_absolute_error: 0.3782\n",
      "Epoch 434/550\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.1863 - mean_absolute_error: 0.2959\n",
      "Epoch 435/550\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.3591 - mean_absolute_error: 0.4943\n",
      "Epoch 436/550\n",
      "28/28 [==============================] - 0s 248us/step - loss: 0.3547 - mean_absolute_error: 0.4990\n",
      "Epoch 437/550\n",
      "28/28 [==============================] - 0s 232us/step - loss: 0.1228 - mean_absolute_error: 0.2596\n",
      "Epoch 438/550\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.4969 - mean_absolute_error: 0.6061\n",
      "Epoch 439/550\n",
      "28/28 [==============================] - 0s 285us/step - loss: 0.1662 - mean_absolute_error: 0.2806\n",
      "Epoch 440/550\n",
      "28/28 [==============================] - 0s 174us/step - loss: 0.1757 - mean_absolute_error: 0.2897\n",
      "Epoch 441/550\n",
      "28/28 [==============================] - 0s 279us/step - loss: 0.2082 - mean_absolute_error: 0.3717\n",
      "Epoch 442/550\n",
      "28/28 [==============================] - 0s 199us/step - loss: 0.1764 - mean_absolute_error: 0.3333\n",
      "Epoch 443/550\n",
      "28/28 [==============================] - 0s 178us/step - loss: 0.1012 - mean_absolute_error: 0.2143\n",
      "Epoch 444/550\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.1961 - mean_absolute_error: 0.3382\n",
      "Epoch 445/550\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.4141 - mean_absolute_error: 0.5835\n",
      "Epoch 446/550\n",
      "28/28 [==============================] - 0s 300us/step - loss: 0.3237 - mean_absolute_error: 0.3705\n",
      "Epoch 447/550\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.2085 - mean_absolute_error: 0.3362\n",
      "Epoch 448/550\n",
      "28/28 [==============================] - 0s 304us/step - loss: 0.3198 - mean_absolute_error: 0.3889\n",
      "Epoch 449/550\n",
      "28/28 [==============================] - 0s 177us/step - loss: 0.4831 - mean_absolute_error: 0.6196\n",
      "Epoch 450/550\n",
      "28/28 [==============================] - 0s 198us/step - loss: 0.3119 - mean_absolute_error: 0.3923\n",
      "Epoch 451/550\n",
      "28/28 [==============================] - 0s 213us/step - loss: 0.1136 - mean_absolute_error: 0.2867\n",
      "Epoch 452/550\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.5488 - mean_absolute_error: 0.5892\n",
      "Epoch 453/550\n",
      "28/28 [==============================] - 0s 249us/step - loss: 0.3225 - mean_absolute_error: 0.5019\n",
      "Epoch 454/550\n",
      "28/28 [==============================] - 0s 220us/step - loss: 0.1348 - mean_absolute_error: 0.2724\n",
      "Epoch 455/550\n",
      "28/28 [==============================] - 0s 164us/step - loss: 0.1861 - mean_absolute_error: 0.3675\n",
      "Epoch 456/550\n",
      "28/28 [==============================] - 0s 231us/step - loss: 0.1909 - mean_absolute_error: 0.3622\n",
      "Epoch 457/550\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0773 - mean_absolute_error: 0.2091\n",
      "Epoch 458/550\n",
      "28/28 [==============================] - 0s 226us/step - loss: 0.2552 - mean_absolute_error: 0.4041\n",
      "Epoch 459/550\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.1727 - mean_absolute_error: 0.2913\n",
      "Epoch 460/550\n",
      "28/28 [==============================] - 0s 227us/step - loss: 0.1339 - mean_absolute_error: 0.2769\n",
      "Epoch 461/550\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.1526 - mean_absolute_error: 0.3019\n",
      "Epoch 462/550\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0962 - mean_absolute_error: 0.2317\n",
      "Epoch 463/550\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0666 - mean_absolute_error: 0.1519\n",
      "Epoch 464/550\n",
      "28/28 [==============================] - 0s 196us/step - loss: 0.0746 - mean_absolute_error: 0.1715\n",
      "Epoch 465/550\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0699 - mean_absolute_error: 0.1692\n",
      "Epoch 466/550\n",
      "28/28 [==============================] - 0s 250us/step - loss: 0.0769 - mean_absolute_error: 0.1651\n",
      "Epoch 467/550\n",
      "28/28 [==============================] - 0s 202us/step - loss: 0.0614 - mean_absolute_error: 0.1642\n",
      "Epoch 468/550\n",
      "28/28 [==============================] - 0s 247us/step - loss: 0.0876 - mean_absolute_error: 0.2545\n",
      "Epoch 469/550\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0603 - mean_absolute_error: 0.1721\n",
      "Epoch 470/550\n",
      "28/28 [==============================] - 0s 159us/step - loss: 0.0476 - mean_absolute_error: 0.1358\n",
      "Epoch 471/550\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0442 - mean_absolute_error: 0.1164\n",
      "Epoch 472/550\n",
      "28/28 [==============================] - 0s 290us/step - loss: 0.0477 - mean_absolute_error: 0.1347\n",
      "Epoch 473/550\n",
      "28/28 [==============================] - 0s 244us/step - loss: 0.0483 - mean_absolute_error: 0.1321\n",
      "Epoch 474/550\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0480 - mean_absolute_error: 0.1357\n",
      "Epoch 475/550\n",
      "28/28 [==============================] - 0s 243us/step - loss: 0.0474 - mean_absolute_error: 0.1155\n",
      "Epoch 476/550\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0419 - mean_absolute_error: 0.1123\n",
      "Epoch 477/550\n",
      "28/28 [==============================] - 0s 279us/step - loss: 0.0391 - mean_absolute_error: 0.1115\n",
      "Epoch 478/550\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0411 - mean_absolute_error: 0.1102\n",
      "Epoch 479/550\n",
      "28/28 [==============================] - 0s 295us/step - loss: 0.0426 - mean_absolute_error: 0.0977\n",
      "Epoch 480/550\n",
      "28/28 [==============================] - 0s 224us/step - loss: 0.0455 - mean_absolute_error: 0.0987\n",
      "Epoch 481/550\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0424 - mean_absolute_error: 0.1024\n",
      "Epoch 482/550\n",
      "28/28 [==============================] - 0s 274us/step - loss: 0.0524 - mean_absolute_error: 0.1302\n",
      "Epoch 483/550\n",
      "28/28 [==============================] - 0s 229us/step - loss: 0.0473 - mean_absolute_error: 0.1468\n",
      "Epoch 484/550\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0494 - mean_absolute_error: 0.1473\n",
      "Epoch 485/550\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0530 - mean_absolute_error: 0.1789\n",
      "Epoch 486/550\n",
      "28/28 [==============================] - 0s 251us/step - loss: 0.0598 - mean_absolute_error: 0.1617\n",
      "Epoch 487/550\n",
      "28/28 [==============================] - 0s 223us/step - loss: 0.0439 - mean_absolute_error: 0.1332\n",
      "Epoch 488/550\n",
      "28/28 [==============================] - 0s 273us/step - loss: 0.0542 - mean_absolute_error: 0.1490\n",
      "Epoch 489/550\n",
      "28/28 [==============================] - 0s 233us/step - loss: 0.0472 - mean_absolute_error: 0.1568\n",
      "Epoch 490/550\n",
      "28/28 [==============================] - 0s 187us/step - loss: 0.0406 - mean_absolute_error: 0.1084\n",
      "Epoch 491/550\n",
      "28/28 [==============================] - ETA: 0s - loss: 0.0469 - mean_absolute_error: 0.111 - 0s 278us/step - loss: 0.0388 - mean_absolute_error: 0.1091\n",
      "Epoch 492/550\n",
      "28/28 [==============================] - 0s 209us/step - loss: 0.0444 - mean_absolute_error: 0.1228\n",
      "Epoch 493/550\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0552 - mean_absolute_error: 0.1320\n",
      "Epoch 494/550\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0569 - mean_absolute_error: 0.1743\n",
      "Epoch 495/550\n",
      "28/28 [==============================] - 0s 186us/step - loss: 0.0370 - mean_absolute_error: 0.1236\n",
      "Epoch 496/550\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0710 - mean_absolute_error: 0.2020\n",
      "Epoch 497/550\n",
      "28/28 [==============================] - 0s 264us/step - loss: 0.0812 - mean_absolute_error: 0.2344\n",
      "Epoch 498/550\n",
      "28/28 [==============================] - 0s 162us/step - loss: 0.0461 - mean_absolute_error: 0.1458\n",
      "Epoch 499/550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 [==============================] - 0s 224us/step - loss: 0.0838 - mean_absolute_error: 0.2262\n",
      "Epoch 500/550\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0768 - mean_absolute_error: 0.2502\n",
      "Epoch 501/550\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0764 - mean_absolute_error: 0.2003\n",
      "Epoch 502/550\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0467 - mean_absolute_error: 0.1338\n",
      "Epoch 503/550\n",
      "28/28 [==============================] - 0s 259us/step - loss: 0.0628 - mean_absolute_error: 0.1858\n",
      "Epoch 504/550\n",
      "28/28 [==============================] - 0s 236us/step - loss: 0.0987 - mean_absolute_error: 0.2637\n",
      "Epoch 505/550\n",
      "28/28 [==============================] - 0s 212us/step - loss: 0.0510 - mean_absolute_error: 0.1687\n",
      "Epoch 506/550\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0364 - mean_absolute_error: 0.1380\n",
      "Epoch 507/550\n",
      "28/28 [==============================] - 0s 189us/step - loss: 0.0904 - mean_absolute_error: 0.2243\n",
      "Epoch 508/550\n",
      "28/28 [==============================] - 0s 183us/step - loss: 0.0986 - mean_absolute_error: 0.2736\n",
      "Epoch 509/550\n",
      "28/28 [==============================] - 0s 177us/step - loss: 0.0481 - mean_absolute_error: 0.1429\n",
      "Epoch 510/550\n",
      "28/28 [==============================] - 0s 217us/step - loss: 0.0688 - mean_absolute_error: 0.2123\n",
      "Epoch 511/550\n",
      "28/28 [==============================] - 0s 174us/step - loss: 0.1767 - mean_absolute_error: 0.3061\n",
      "Epoch 512/550\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0815 - mean_absolute_error: 0.2452\n",
      "Epoch 513/550\n",
      "28/28 [==============================] - 0s 185us/step - loss: 0.0551 - mean_absolute_error: 0.1758\n",
      "Epoch 514/550\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0546 - mean_absolute_error: 0.1724\n",
      "Epoch 515/550\n",
      "28/28 [==============================] - 0s 256us/step - loss: 0.1008 - mean_absolute_error: 0.2121\n",
      "Epoch 516/550\n",
      "28/28 [==============================] - 0s 241us/step - loss: 0.0672 - mean_absolute_error: 0.2206\n",
      "Epoch 517/550\n",
      "28/28 [==============================] - 0s 228us/step - loss: 0.0454 - mean_absolute_error: 0.1181\n",
      "Epoch 518/550\n",
      "28/28 [==============================] - 0s 222us/step - loss: 0.0230 - mean_absolute_error: 0.1030\n",
      "Epoch 519/550\n",
      "28/28 [==============================] - 0s 172us/step - loss: 0.0705 - mean_absolute_error: 0.1986\n",
      "Epoch 520/550\n",
      "28/28 [==============================] - 0s 269us/step - loss: 0.0756 - mean_absolute_error: 0.2472\n",
      "Epoch 521/550\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0406 - mean_absolute_error: 0.1383\n",
      "Epoch 522/550\n",
      "28/28 [==============================] - 0s 254us/step - loss: 0.0562 - mean_absolute_error: 0.1719\n",
      "Epoch 523/550\n",
      "28/28 [==============================] - 0s 191us/step - loss: 0.0665 - mean_absolute_error: 0.1975\n",
      "Epoch 524/550\n",
      "28/28 [==============================] - 0s 174us/step - loss: 0.0469 - mean_absolute_error: 0.1762\n",
      "Epoch 525/550\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0275 - mean_absolute_error: 0.0942\n",
      "Epoch 526/550\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0444 - mean_absolute_error: 0.1615\n",
      "Epoch 527/550\n",
      "28/28 [==============================] - 0s 195us/step - loss: 0.0842 - mean_absolute_error: 0.2110\n",
      "Epoch 528/550\n",
      "28/28 [==============================] - 0s 261us/step - loss: 0.0431 - mean_absolute_error: 0.1593\n",
      "Epoch 529/550\n",
      "28/28 [==============================] - 0s 240us/step - loss: 0.0225 - mean_absolute_error: 0.0982\n",
      "Epoch 530/550\n",
      "28/28 [==============================] - 0s 295us/step - loss: 0.0466 - mean_absolute_error: 0.1630\n",
      "Epoch 531/550\n",
      "28/28 [==============================] - 0s 201us/step - loss: 0.0685 - mean_absolute_error: 0.2011\n",
      "Epoch 532/550\n",
      "28/28 [==============================] - 0s 234us/step - loss: 0.0256 - mean_absolute_error: 0.1082\n",
      "Epoch 533/550\n",
      "28/28 [==============================] - 0s 207us/step - loss: 0.0407 - mean_absolute_error: 0.1514\n",
      "Epoch 534/550\n",
      "28/28 [==============================] - 0s 242us/step - loss: 0.0372 - mean_absolute_error: 0.1490\n",
      "Epoch 535/550\n",
      "28/28 [==============================] - 0s 204us/step - loss: 0.0232 - mean_absolute_error: 0.0980\n",
      "Epoch 536/550\n",
      "28/28 [==============================] - 0s 175us/step - loss: 0.0219 - mean_absolute_error: 0.0833\n",
      "Epoch 537/550\n",
      "28/28 [==============================] - 0s 246us/step - loss: 0.0203 - mean_absolute_error: 0.0860\n",
      "Epoch 538/550\n",
      "28/28 [==============================] - 0s 200us/step - loss: 0.0243 - mean_absolute_error: 0.0966\n",
      "Epoch 539/550\n",
      "28/28 [==============================] - 0s 181us/step - loss: 0.0192 - mean_absolute_error: 0.0713\n",
      "Epoch 540/550\n",
      "28/28 [==============================] - 0s 230us/step - loss: 0.0260 - mean_absolute_error: 0.1003\n",
      "Epoch 541/550\n",
      "28/28 [==============================] - 0s 197us/step - loss: 0.0225 - mean_absolute_error: 0.0917\n",
      "Epoch 542/550\n",
      "28/28 [==============================] - 0s 235us/step - loss: 0.0193 - mean_absolute_error: 0.0852\n",
      "Epoch 543/550\n",
      "28/28 [==============================] - 0s 215us/step - loss: 0.0174 - mean_absolute_error: 0.0808\n",
      "Epoch 544/550\n",
      "28/28 [==============================] - 0s 165us/step - loss: 0.0216 - mean_absolute_error: 0.1017\n",
      "Epoch 545/550\n",
      "28/28 [==============================] - 0s 211us/step - loss: 0.0177 - mean_absolute_error: 0.0795\n",
      "Epoch 546/550\n",
      "28/28 [==============================] - 0s 218us/step - loss: 0.0216 - mean_absolute_error: 0.1037\n",
      "Epoch 547/550\n",
      "28/28 [==============================] - 0s 184us/step - loss: 0.0176 - mean_absolute_error: 0.0788\n",
      "Epoch 548/550\n",
      "28/28 [==============================] - 0s 193us/step - loss: 0.0320 - mean_absolute_error: 0.1253\n",
      "Epoch 549/550\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0162 - mean_absolute_error: 0.0931\n",
      "Epoch 550/550\n",
      "28/28 [==============================] - 0s 203us/step - loss: 0.0215 - mean_absolute_error: 0.1043\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff5987f4ac8>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=20, nb_epoch=550,\n",
    "         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1120.229736328125, 22.41884422302246]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict(X_test)\n",
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-158.88431] -119.24\n",
      "[-58.795765] -33.11\n",
      "[-91.11286] -101.2\n",
      "[-120.40375] -120.95\n",
      "[-130.07736] -123.81\n",
      "[-78.381676] -112.27\n",
      "[-135.72801] -128.54\n",
      "[-84.03625] -80.4\n",
      "[-107.53012] -102.9\n",
      "[-119.77787] -109.21\n",
      "[-16.535288] -102.12\n",
      "[-97.23563] -105.78\n",
      "[-142.97832] -183.27\n",
      "[-145.90071] -99.87\n",
      "[-88.71719] -113.0\n",
      "[-104.636] -118.6\n",
      "[-180.00963] -159.6\n",
      "[-119.77389] -113.38\n",
      "[-68.15801] -116.8\n",
      "[-111.19192] -109.04\n",
      "[-129.31192] -118.28\n",
      "[-113.76264] -122.2\n",
      "[-112.42995] -113.2\n",
      "[-115.67008] -114.9\n",
      "[-113.407394] -116.0\n",
      "[-128.53154] -107.38\n",
      "[-58.438587] -100.7\n",
      "[-118.82553] -16.55\n"
     ]
    }
   ],
   "source": [
    "for i in range(predict.shape[0]):\n",
    "    print(predict[i], y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = model.predict(X_test)\n",
    "res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-169.10940776634808 -119.24\n",
      "-24.39971748932163 -33.11\n",
      "-88.26222114959788 -101.2\n",
      "-143.29018458488468 -120.95\n",
      "-127.76588905070558 -123.81\n",
      "-49.16921733212732 -112.27\n",
      "-119.5828482283568 -128.54\n",
      "-113.97280047452713 -80.4\n",
      "-164.63558815241512 -102.9\n",
      "-119.77026588226695 -109.21\n",
      "-5.800983171659681 -102.12\n",
      "-132.10175794974512 -105.78\n",
      "-203.6869016110275 -183.27\n",
      "-154.58394385595105 -99.87\n",
      "-107.92389788554505 -113.0\n",
      "-72.43737167462041 -118.6\n",
      "-205.95865033220966 -159.6\n",
      "-159.1803236374369 -113.38\n",
      "-71.33896968169051 -116.8\n",
      "-121.820198112769 -109.04\n",
      "-147.47112770216495 -118.28\n",
      "-157.31401809465564 -122.2\n",
      "-150.8458979035488 -113.2\n",
      "-120.23747328608617 -114.9\n",
      "-130.44505410008819 -116.0\n",
      "-143.79622582895257 -107.38\n",
      "-69.08408819506872 -100.7\n",
      "-159.19078305161293 -16.55\n"
     ]
    }
   ],
   "source": [
    "for i in range(res.shape[0]):\n",
    "    print(res[i], y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
